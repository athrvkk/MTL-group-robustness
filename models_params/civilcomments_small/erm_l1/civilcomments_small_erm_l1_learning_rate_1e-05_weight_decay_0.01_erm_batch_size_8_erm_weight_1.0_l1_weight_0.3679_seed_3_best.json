{
    "config": {
        "dataset": "civilcomments_subsamples",
        "method": "erm_l1",
        "seed": 3,
        "learning_rate": 1e-05,
        "weight_decay": 0.01,
        "erm_batch_size": 8,
        "erm_weight": 1.0,
        "l1_weight": 0.3679
    },
    "best_results": {
        "epoch": 3,
        "tr_loss": 0.11463315784931183,
        "min_acc_tr": 0.98094283,
        "avg_acc_tr": 0.9891793754538852,
        "group_wise_acc_tr": [
            0.98392215,
            0.99420563,
            0.98094283,
            0.9824
        ],
        "va_loss": 1.093482971060439,
        "min_acc_va": 0.62962963,
        "avg_acc_va": 0.803825404610103,
        "group_wise_acc_va": [
            0.9133574,
            0.87164179,
            0.74576271,
            0.87943262,
            0.83108108,
            0.7628866,
            0.82242991,
            0.77272727,
            0.67123288,
            0.64285714,
            0.62962963,
            0.7254902,
            0.72857143,
            0.70588235,
            0.65671642,
            0.6625
        ],
        "min_acc_te": 0.6433121,
        "avg_acc_te": 0.8105219893136046,
        "group_wise_acc_te": [
            0.86901408,
            0.87032419,
            0.71217712,
            0.9167842,
            0.82620321,
            0.81102362,
            0.77031802,
            0.78421053,
            0.71794872,
            0.70760234,
            0.71666667,
            0.74766355,
            0.65909091,
            0.70833333,
            0.6433121,
            0.69642857
        ],
        "l1_loss": 0.007425996009260416
    }
}