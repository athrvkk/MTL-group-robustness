{
    "config": {
        "dataset": "civilcomments_subsamples",
        "method": "erm_mt",
        "seed": 3,
        "learning_rate": 1e-05,
        "weight_decay": 0.01,
        "erm_batch_size": 32,
        "erm_weight": 1.0,
        "mt_batch_size": 32,
        "mt_weight": 0.3679
    },
    "best_results": {
        "epoch": 6,
        "tr_loss": 0.9275937080383301,
        "min_acc_tr": 0.97080601,
        "avg_acc_tr": 0.9840958605664488,
        "group_wise_acc_tr": [
            0.97080601,
            0.99124107,
            0.99297894,
            0.9856
        ],
        "va_loss": 0.6545566753484309,
        "min_acc_va": 0.6779661,
        "avg_acc_va": 0.7832270720941638,
        "group_wise_acc_va": [
            0.84837545,
            0.82985075,
            0.6779661,
            0.85815603,
            0.73648649,
            0.68041237,
            0.73831776,
            0.69886364,
            0.78082192,
            0.71428571,
            0.7962963,
            0.82352941,
            0.78571429,
            0.73529412,
            0.7761194,
            0.7625
        ],
        "min_acc_te": 0.6819788,
        "avg_acc_te": 0.7971639950678175,
        "group_wise_acc_te": [
            0.82676056,
            0.8478803,
            0.6900369,
            0.8899859,
            0.7486631,
            0.75984252,
            0.6819788,
            0.71315789,
            0.76923077,
            0.78947368,
            0.78333333,
            0.81308411,
            0.77272727,
            0.77777778,
            0.82165605,
            0.79761905
        ],
        "erm_loss": 0.06164659932255745,
        "mt_loss": 0.8659476041793823
    }
}