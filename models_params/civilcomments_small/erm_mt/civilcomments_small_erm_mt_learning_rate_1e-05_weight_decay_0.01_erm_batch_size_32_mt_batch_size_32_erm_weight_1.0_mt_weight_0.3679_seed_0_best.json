{
    "config": {
        "dataset": "civilcomments_subsamples",
        "method": "erm_mt",
        "seed": 0,
        "learning_rate": 1e-05,
        "weight_decay": 0.01,
        "erm_batch_size": 32,
        "erm_weight": 1.0,
        "mt_batch_size": 32,
        "mt_weight": 0.3679
    },
    "best_results": {
        "epoch": 4,
        "tr_loss": 1.001544713973999,
        "min_acc_tr": 0.94182357,
        "avg_acc_tr": 0.9663035584604212,
        "group_wise_acc_tr": [
            0.94182357,
            0.98126937,
            0.97492477,
            0.96
        ],
        "va_loss": 0.48141903849318624,
        "min_acc_va": 0.6728972,
        "avg_acc_va": 0.7817557626287396,
        "group_wise_acc_va": [
            0.84115523,
            0.8238806,
            0.68644068,
            0.89007092,
            0.78378378,
            0.71134021,
            0.6728972,
            0.70454545,
            0.79452055,
            0.71428571,
            0.7037037,
            0.78431373,
            0.7,
            0.67647059,
            0.76119403,
            0.7875
        ],
        "min_acc_te": 0.6900369,
        "avg_acc_te": 0.8055898068228524,
        "group_wise_acc_te": [
            0.84366197,
            0.85286783,
            0.6900369,
            0.91114245,
            0.79411765,
            0.78740157,
            0.70671378,
            0.72105263,
            0.76923077,
            0.74853801,
            0.83333333,
            0.76635514,
            0.71212121,
            0.70833333,
            0.77070064,
            0.81547619
        ],
        "erm_loss": 0.12392542511224747,
        "mt_loss": 0.8776190280914307
    }
}