{
    "config": {
        "dataset": "civilcomments_subsamples",
        "method": "erm_mt",
        "seed": 2,
        "learning_rate": 1e-05,
        "weight_decay": 0.01,
        "erm_batch_size": 32,
        "erm_weight": 1.0,
        "mt_batch_size": 32,
        "mt_weight": 0.3679
    },
    "best_results": {
        "epoch": 7,
        "tr_loss": 0.8849281668663025,
        "min_acc_tr": 0.98984557,
        "avg_acc_tr": 0.9951343500363108,
        "group_wise_acc_tr": [
            0.98984557,
            0.99838297,
            0.99699097,
            0.9936
        ],
        "va_loss": 1.025254251435399,
        "min_acc_va": 0.62857143,
        "avg_acc_va": 0.7650809220205983,
        "group_wise_acc_va": [
            0.86281588,
            0.85671642,
            0.68644068,
            0.85460993,
            0.77702703,
            0.68041237,
            0.65420561,
            0.67045455,
            0.68493151,
            0.62857143,
            0.7037037,
            0.70588235,
            0.64285714,
            0.76470588,
            0.74626866,
            0.675
        ],
        "min_acc_te": 0.67844523,
        "avg_acc_te": 0.8076448828606658,
        "group_wise_acc_te": [
            0.85492958,
            0.88528678,
            0.70110701,
            0.90973202,
            0.76737968,
            0.80708661,
            0.67844523,
            0.72105263,
            0.73717949,
            0.73684211,
            0.76666667,
            0.76635514,
            0.70454545,
            0.73611111,
            0.8089172,
            0.78571429
        ],
        "erm_loss": 0.03133459389209747,
        "mt_loss": 0.8535940051078796
    }
}