{
    "config": {
        "dataset": "civilcomments_subsamples",
        "method": "erm",
        "seed": 4,
        "learning_rate": 1e-05,
        "weight_decay": 0.01,
        "erm_batch_size": 8,
        "erm_weight": 1.0
    },
    "best_results": {
        "epoch": 3,
        "tr_loss": 0.06853305431510935,
        "min_acc_tr": 0.9832875,
        "avg_acc_tr": 0.9891067538126361,
        "group_wise_acc_tr": [
            0.9832875,
            0.99178008,
            0.99598796,
            0.9904
        ],
        "va_loss": 1.1465246851979436,
        "min_acc_va": 0.64285714,
        "avg_acc_va": 0.7802844531633154,
        "group_wise_acc_va": [
            0.85559567,
            0.86567164,
            0.69491525,
            0.88652482,
            0.81081081,
            0.75257732,
            0.73831776,
            0.71590909,
            0.68493151,
            0.65714286,
            0.66666667,
            0.74509804,
            0.64285714,
            0.64705882,
            0.65671642,
            0.6625
        ],
        "min_acc_te": 0.68634686,
        "avg_acc_te": 0.8086724208795726,
        "group_wise_acc_te": [
            0.84647887,
            0.87157107,
            0.68634686,
            0.89703808,
            0.80481283,
            0.81889764,
            0.74204947,
            0.73157895,
            0.76923077,
            0.76023392,
            0.76666667,
            0.77570093,
            0.70454545,
            0.73611111,
            0.77070064,
            0.73809524
        ]
    }
}