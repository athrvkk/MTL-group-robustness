{
    "config": {
        "dataset": "civilcomments_subsamples",
        "method": "jtt",
        "seed": 0,
        "learning_rate": 1e-05,
        "weight_decay": 0.01,
        "erm_batch_size": 8,
        "T": 5,
        "up": 6,
        "erm_weight": 1.0
    },
    "best_results": {
        "epoch": 5,
        "tr_loss": 0.0,
        "min_acc_tr": 0.99090332,
        "avg_acc_tr": 0.9946986201888163,
        "group_wise_acc_tr": [
            0.99090332,
            0.99676593,
            0.99598796,
            0.9968
        ],
        "va_loss": 1.0651379478455056,
        "min_acc_va": 0.64705882,
        "avg_acc_va": 0.815105443845022,
        "group_wise_acc_va": [
            0.90252708,
            0.91044776,
            0.76271186,
            0.91843972,
            0.81081081,
            0.7628866,
            0.80373832,
            0.77272727,
            0.68493151,
            0.67142857,
            0.64814815,
            0.7254902,
            0.7,
            0.64705882,
            0.65671642,
            0.725
        ],
        "min_acc_te": 0.65277778,
        "avg_acc_te": 0.8168927250308261,
        "group_wise_acc_te": [
            0.88732394,
            0.89401496,
            0.73800738,
            0.91537377,
            0.79144385,
            0.7992126,
            0.76678445,
            0.78684211,
            0.70512821,
            0.70760234,
            0.74166667,
            0.71028037,
            0.67424242,
            0.65277778,
            0.70700637,
            0.7202381
        ]
    }
}