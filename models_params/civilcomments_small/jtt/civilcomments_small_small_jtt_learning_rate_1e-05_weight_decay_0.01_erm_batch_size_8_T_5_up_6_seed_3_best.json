{
    "config": {
        "dataset": "civilcomments_subsamples",
        "method": "jtt",
        "seed": 3,
        "learning_rate": 1e-05,
        "weight_decay": 0.01,
        "erm_batch_size": 8,
        "T": 5,
        "up": 6,
        "erm_weight": 1.0
    },
    "best_results": {
        "epoch": 9,
        "tr_loss": 0.059711979649824,
        "min_acc_tr": 0.9904,
        "avg_acc_tr": 0.9940450254175744,
        "group_wise_acc_tr": [
            0.99132642,
            0.99595742,
            0.99498495,
            0.9904
        ],
        "va_loss": 1.1569301877524327,
        "min_acc_va": 0.55714286,
        "avg_acc_va": 0.7954879843060324,
        "group_wise_acc_va": [
            0.89169675,
            0.88955224,
            0.77966102,
            0.89716312,
            0.80405405,
            0.79381443,
            0.74766355,
            0.72727273,
            0.61643836,
            0.55714286,
            0.7037037,
            0.7254902,
            0.64285714,
            0.67647059,
            0.68656716,
            0.6875
        ],
        "min_acc_te": 0.68055556,
        "avg_acc_te": 0.8253185367858611,
        "group_wise_acc_te": [
            0.87464789,
            0.90149626,
            0.75276753,
            0.92242595,
            0.8315508,
            0.84645669,
            0.7385159,
            0.76315789,
            0.71794872,
            0.73684211,
            0.75,
            0.72897196,
            0.71212121,
            0.68055556,
            0.71974522,
            0.75595238
        ]
    }
}