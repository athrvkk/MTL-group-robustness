{
    "config": {
        "dataset": "civilcomments_subsamples",
        "method": "jtt",
        "seed": 1,
        "learning_rate": 1e-05,
        "weight_decay": 0.01,
        "erm_batch_size": 8,
        "T": 5,
        "up": 6,
        "erm_weight": 1.0
    },
    "best_results": {
        "epoch": 3,
        "tr_loss": 0.06247138561406843,
        "min_acc_tr": 0.98836471,
        "avg_acc_tr": 0.9934640522875817,
        "group_wise_acc_tr": [
            0.98836471,
            0.99649643,
            0.99297894,
            0.9968
        ],
        "va_loss": 1.1047003779486142,
        "min_acc_va": 0.67142857,
        "avg_acc_va": 0.7949975478175576,
        "group_wise_acc_va": [
            0.88808664,
            0.85970149,
            0.72881356,
            0.88652482,
            0.80405405,
            0.74226804,
            0.70093458,
            0.70454545,
            0.7260274,
            0.67142857,
            0.68518519,
            0.78431373,
            0.77142857,
            0.73529412,
            0.67164179,
            0.75
        ],
        "min_acc_te": 0.70760234,
        "avg_acc_te": 0.8127825729551993,
        "group_wise_acc_te": [
            0.86901408,
            0.86783042,
            0.74538745,
            0.91819464,
            0.78342246,
            0.80708661,
            0.73144876,
            0.78421053,
            0.73076923,
            0.70760234,
            0.71666667,
            0.74766355,
            0.71212121,
            0.72222222,
            0.7133758,
            0.75595238
        ]
    }
}